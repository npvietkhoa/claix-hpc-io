{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorep_result_dir = './scorep-results'\n",
    "\n",
    "# get all files in the directory\n",
    "scorep_result_dir = './scorep-results'\n",
    "scorep_result_dir = glob.glob(os.path.join(scorep_result_dir, '*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "otf2_trace = \"./scorep-results/bt.C.4.mpi_io_full\" + '/traces.otf2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import otf2.reader\n",
    "from otf2.events import Enter\n",
    "def extract_unique_functions(trace_file_path: str) -> set:\n",
    "    \"\"\"\n",
    "    Extract unique function names from an OTF2 trace file.\n",
    "    \n",
    "    Args:\n",
    "        trace_file_path (str): Path to the OTF2 trace file\n",
    "            Example: './path/to/traces.otf2'\n",
    "    \n",
    "    Returns:\n",
    "        set[str]: Set of unique function names found in the trace\n",
    "            Example: {'MPI_Init', 'MPI_Finalize', 'MPI_Barrier'}\n",
    "    \n",
    "    Raises:\n",
    "        ValueError: If file path doesn't end with .otf2\n",
    "        FileNotFoundError: If trace file doesn't exist\n",
    "    \"\"\"\n",
    "    # Validate input file\n",
    "    if not trace_file_path.endswith('.otf2'):\n",
    "        raise ValueError(\"Input file must be an .otf2 trace file\")\n",
    "    \n",
    "    if not os.path.exists(trace_file_path):\n",
    "        raise FileNotFoundError(f\"Trace file not found: {trace_file_path}\")\n",
    "\n",
    "    unique_functions = set()\n",
    "    \n",
    "    try:\n",
    "        with otf2.reader.open(trace_file_path) as trace:\n",
    "            for _, event in trace.events:\n",
    "                if isinstance(event, Enter):\n",
    "                    unique_functions.add(event.region.name)\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error reading trace file: {str(e)}\")\n",
    "            \n",
    "    return unique_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MPI_Allreduce',\n",
       " 'MPI_Barrier',\n",
       " 'MPI_Bcast',\n",
       " 'MPI_Comm_dup',\n",
       " 'MPI_Comm_rank',\n",
       " 'MPI_Comm_size',\n",
       " 'MPI_File_close',\n",
       " 'MPI_File_delete',\n",
       " 'MPI_File_open',\n",
       " 'MPI_File_read_at_all',\n",
       " 'MPI_File_set_view',\n",
       " 'MPI_File_write_at_all',\n",
       " 'MPI_Finalize',\n",
       " 'MPI_Init',\n",
       " 'MPI_Irecv',\n",
       " 'MPI_Isend',\n",
       " 'MPI_Reduce',\n",
       " 'MPI_Wait',\n",
       " 'MPI_Waitall'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_unique_functions(otf2_trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from otf2.events import Enter, Leave\n",
    "\n",
    "def calculate_accumulated_function_time(otf2_trace: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate timing metrics from an OTF2 trace file.\n",
    "    \n",
    "    Returns DataFrame with columns:\n",
    "    - Function: Name of the function\n",
    "    - Total Time (s): Total time spent in function\n",
    "    - Call Count: Number of invocations\n",
    "    - Average Time (s): Mean time per call\n",
    "    \n",
    "    Usage:\n",
    "    >>> otf2_trace = \"./scorep-results/bt.C.4.mpi_io_full/traces.otf2\"\n",
    "    >>> df = calculate_accumulated_function_time(otf2_trace)\n",
    "    >>> print(df)\n",
    "    \n",
    "    Results:\n",
    "    >>> df.head()\n",
    "          Function  Total Time (s)  Call Count  Average Time (s)\n",
    "    0  MPI_Init          0.123456          10          0.012346\n",
    "    1  MPI_Finalize      0.234567          20          0.011728\n",
    "    2  MPI_Barrier       0.345678          30          0.011523\n",
    "    3  MPI_Bcast         0.456789          40          0.011420\n",
    "    4  MPI_Reduce        0.567890          50          0.011358\n",
    "    \"\"\"\n",
    "    # Input validation\n",
    "    if not otf2_trace.endswith('.otf2'):\n",
    "        raise ValueError(\"Input file must be an .otf2 trace file\")\n",
    "    \n",
    "    # Initialize tracking dictionaries\n",
    "    metrics = {\n",
    "        'times': defaultdict(float),  # Track total time spent in each function\n",
    "        'counts': defaultdict(int)    # Track number of calls to each function\n",
    "    }\n",
    "    call_stacks = defaultdict(list)\n",
    "    \n",
    "    # Process trace events\n",
    "    with otf2.reader.open(otf2_trace) as trace:\n",
    "        resolution = trace.timer_resolution\n",
    "        \n",
    "        for location, event in trace.events:\n",
    "            if isinstance(event, Enter):\n",
    "                call_stacks[location].append((event.region, event.time))\n",
    "                metrics['counts'][event.region] += 1\n",
    "                \n",
    "            elif isinstance(event, Leave):\n",
    "                if not call_stacks[location]:\n",
    "                    raise RuntimeError(f\"Unmatched Leave event in {location.name}\")\n",
    "                    \n",
    "                region, start_time = call_stacks[location].pop()\n",
    "                if region != event.region:\n",
    "                    raise RuntimeError(f\"Mismatched Enter/Leave in {location.name}\")\n",
    "                \n",
    "                duration = (event.time - start_time) / resolution\n",
    "                metrics['times'][region] += duration\n",
    "    \n",
    "\n",
    "    function_names = [fn.name for fn in metrics['times']]\n",
    "    total_times = list(metrics['times'].values())\n",
    "    call_counts = [metrics['counts'][fn] for fn in metrics['times']]\n",
    "    avg_times = [metrics['times'][fn] / metrics['counts'][fn] for fn in metrics['times']]          \n",
    "    return pd.DataFrame({\n",
    "        'Function': function_names,\n",
    "        'Total Time (s)': total_times,\n",
    "        'Call Count': call_counts,\n",
    "        'Average Time (s)': avg_times\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Function",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Total Time (s)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Call Count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Average Time (s)",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "28df69d8-70e2-47d0-b8ef-94835c07cbd8",
       "rows": [
        [
         "0",
         "MPI_Init",
         "3.5711431373642006",
         "4",
         "0.8927857843410502"
        ],
        [
         "1",
         "MPI_Comm_size",
         "6.716190070020886e-06",
         "4",
         "1.6790475175052215e-06"
        ],
        [
         "2",
         "MPI_Comm_rank",
         "1.9942855936789188e-06",
         "4",
         "4.985713984197297e-07"
        ],
        [
         "3",
         "MPI_Comm_dup",
         "0.002375367475394443",
         "8",
         "0.0002969209344243054"
        ],
        [
         "4",
         "MPI_Bcast",
         "0.0030225341029229383",
         "32",
         "9.445419071634182e-05"
        ],
        [
         "5",
         "MPI_File_delete",
         "0.035998068299164444",
         "1",
         "0.035998068299164444"
        ],
        [
         "6",
         "MPI_Barrier",
         "0.11227617225758385",
         "12",
         "0.009356347688131988"
        ],
        [
         "7",
         "MPI_File_open",
         "0.23333822207906946",
         "8",
         "0.029167277759883682"
        ],
        [
         "8",
         "MPI_File_set_view",
         "0.002925956013525517",
         "8",
         "0.00036574450169068963"
        ],
        [
         "9",
         "MPI_Irecv",
         "0.013122010635002217",
         "9672",
         "1.3567008514270284e-06"
        ],
        [
         "10",
         "MPI_Isend",
         "0.6675703320088404",
         "9672",
         "6.902091935575273e-05"
        ],
        [
         "11",
         "MPI_Waitall",
         "0.5981383043030648",
         "808",
         "0.000740270178592902"
        ],
        [
         "12",
         "MPI_Wait",
         "10.193293131167502",
         "9648",
         "0.0010565187739601475"
        ],
        [
         "13",
         "MPI_File_write_at_all",
         "20.86523794195941",
         "160",
         "0.13040773713724632"
        ],
        [
         "14",
         "MPI_File_close",
         "0.00111374755169241",
         "8",
         "0.00013921844396155126"
        ],
        [
         "15",
         "MPI_File_read_at_all",
         "12.750574819846191",
         "160",
         "0.0796910926240387"
        ],
        [
         "16",
         "MPI_Allreduce",
         "0.11127367041344946",
         "164",
         "0.0006784979903259114"
        ],
        [
         "17",
         "MPI_Reduce",
         "0.00017586665603092126",
         "8",
         "2.1983332003865158e-05"
        ],
        [
         "18",
         "MPI_Finalize",
         "5.577904424574352e-05",
         "4",
         "1.394476106143588e-05"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 19
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Function</th>\n",
       "      <th>Total Time (s)</th>\n",
       "      <th>Call Count</th>\n",
       "      <th>Average Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MPI_Init</td>\n",
       "      <td>3.571143</td>\n",
       "      <td>4</td>\n",
       "      <td>8.927858e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MPI_Comm_size</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>4</td>\n",
       "      <td>1.679048e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MPI_Comm_rank</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>4</td>\n",
       "      <td>4.985714e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MPI_Comm_dup</td>\n",
       "      <td>0.002375</td>\n",
       "      <td>8</td>\n",
       "      <td>2.969209e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MPI_Bcast</td>\n",
       "      <td>0.003023</td>\n",
       "      <td>32</td>\n",
       "      <td>9.445419e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MPI_File_delete</td>\n",
       "      <td>0.035998</td>\n",
       "      <td>1</td>\n",
       "      <td>3.599807e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MPI_Barrier</td>\n",
       "      <td>0.112276</td>\n",
       "      <td>12</td>\n",
       "      <td>9.356348e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MPI_File_open</td>\n",
       "      <td>0.233338</td>\n",
       "      <td>8</td>\n",
       "      <td>2.916728e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MPI_File_set_view</td>\n",
       "      <td>0.002926</td>\n",
       "      <td>8</td>\n",
       "      <td>3.657445e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MPI_Irecv</td>\n",
       "      <td>0.013122</td>\n",
       "      <td>9672</td>\n",
       "      <td>1.356701e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MPI_Isend</td>\n",
       "      <td>0.667570</td>\n",
       "      <td>9672</td>\n",
       "      <td>6.902092e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MPI_Waitall</td>\n",
       "      <td>0.598138</td>\n",
       "      <td>808</td>\n",
       "      <td>7.402702e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MPI_Wait</td>\n",
       "      <td>10.193293</td>\n",
       "      <td>9648</td>\n",
       "      <td>1.056519e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MPI_File_write_at_all</td>\n",
       "      <td>20.865238</td>\n",
       "      <td>160</td>\n",
       "      <td>1.304077e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MPI_File_close</td>\n",
       "      <td>0.001114</td>\n",
       "      <td>8</td>\n",
       "      <td>1.392184e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MPI_File_read_at_all</td>\n",
       "      <td>12.750575</td>\n",
       "      <td>160</td>\n",
       "      <td>7.969109e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MPI_Allreduce</td>\n",
       "      <td>0.111274</td>\n",
       "      <td>164</td>\n",
       "      <td>6.784980e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MPI_Reduce</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>8</td>\n",
       "      <td>2.198333e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MPI_Finalize</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>4</td>\n",
       "      <td>1.394476e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Function  Total Time (s)  Call Count  Average Time (s)\n",
       "0                MPI_Init        3.571143           4      8.927858e-01\n",
       "1           MPI_Comm_size        0.000007           4      1.679048e-06\n",
       "2           MPI_Comm_rank        0.000002           4      4.985714e-07\n",
       "3            MPI_Comm_dup        0.002375           8      2.969209e-04\n",
       "4               MPI_Bcast        0.003023          32      9.445419e-05\n",
       "5         MPI_File_delete        0.035998           1      3.599807e-02\n",
       "6             MPI_Barrier        0.112276          12      9.356348e-03\n",
       "7           MPI_File_open        0.233338           8      2.916728e-02\n",
       "8       MPI_File_set_view        0.002926           8      3.657445e-04\n",
       "9               MPI_Irecv        0.013122        9672      1.356701e-06\n",
       "10              MPI_Isend        0.667570        9672      6.902092e-05\n",
       "11            MPI_Waitall        0.598138         808      7.402702e-04\n",
       "12               MPI_Wait       10.193293        9648      1.056519e-03\n",
       "13  MPI_File_write_at_all       20.865238         160      1.304077e-01\n",
       "14         MPI_File_close        0.001114           8      1.392184e-04\n",
       "15   MPI_File_read_at_all       12.750575         160      7.969109e-02\n",
       "16          MPI_Allreduce        0.111274         164      6.784980e-04\n",
       "17             MPI_Reduce        0.000176           8      2.198333e-05\n",
       "18           MPI_Finalize        0.000056           4      1.394476e-05"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_accumulated_function_time(otf2_trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beautify_df(df: pd.DataFrame, top_n: int = 10) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Beautify the DataFrame by sorting and aggregating smaller values.\n",
    "    \n",
    "    Parameters:\n",
    "    It then aggregates the rows beyond the top_n into a single row labeled 'others'.\n",
    "    The resulting DataFrame is reset to have a continuous index.\n",
    "    \n",
    "    Parameters:\n",
    "    dataframe (pd.DataFrame): The input DataFrame with at least a 'Total Time (s)' column.\n",
    "    top_n (int): The number of top rows to retain before aggregating the rest. Default is 10.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: A beautified DataFrame with the top_n rows and an aggregated 'others' row.\n",
    "    \n",
    "    Usage:\n",
    "    >>> df = pd.DataFrame({\n",
    "    >>>     'Function': ['A', 'B', 'C', 'D', 'E'],\n",
    "    >>>     'Total Time (s)': [10, 9, 8, 7, 6],\n",
    "    >>>     'Call Count': [100, 90, 80, 70, 60],\n",
    "    >>>     'Average Time (s)': [0.1, 0.1, 0.1, 0.1, 0.1]\n",
    "    >>> })\n",
    "    >>> beautified_df = beautify_df(df, top_n=3)\n",
    "    >>> print(beautified_df)\n",
    "    \n",
    "    Results:\n",
    "    >>> beautified_df\n",
    "      Function  Total Time (s)  Call Count  Average Time (s)\n",
    "    0        A           10.00         100              0.10\n",
    "    1        B            9.00          90              0.10\n",
    "    2        C            8.00          80              0.10\n",
    "    3   others           22.00         270              0.10\n",
    "    \"\"\"\n",
    "    # Sort the DataFrame by 'Total Time (s)' in descending order\n",
    "    sorted_df = df.sort_values(['Total Time (s)'], ascending=[False])\n",
    "    \n",
    "    # Aggregate rows beyond the top_n into a single row labeled 'others'\n",
    "    remaining_df = sorted_df[top_n:].drop(columns='Function').agg('sum').to_frame().T\n",
    "    remaining_df.insert(0, 'Function', 'others')\n",
    "    \n",
    "    # Concatenate top rows with the aggregated 'others' row\n",
    "    result_df = pd.concat([sorted_df.head(top_n), remaining_df]).reset_index(drop=True)\n",
    "\n",
    "    return result_df.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Function",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Total Time (s)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Call Count",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Average Time (s)",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "59cf59c5-d953-4e20-aa10-4f9d7f2d9d5c",
       "rows": [
        [
         "0",
         "MPI_File_write_at_all",
         "20.8652",
         "160.0",
         "0.1304"
        ],
        [
         "1",
         "MPI_File_read_at_all",
         "12.7506",
         "160.0",
         "0.0797"
        ],
        [
         "2",
         "MPI_Wait",
         "10.1933",
         "9648.0",
         "0.0011"
        ],
        [
         "3",
         "MPI_Init",
         "3.5711",
         "4.0",
         "0.8928"
        ],
        [
         "4",
         "MPI_Isend",
         "0.6676",
         "9672.0",
         "0.0001"
        ],
        [
         "5",
         "others",
         "1.1138",
         "10741.0",
         "0.0769"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 6
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Function</th>\n",
       "      <th>Total Time (s)</th>\n",
       "      <th>Call Count</th>\n",
       "      <th>Average Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MPI_File_write_at_all</td>\n",
       "      <td>20.8652</td>\n",
       "      <td>160.0</td>\n",
       "      <td>0.1304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MPI_File_read_at_all</td>\n",
       "      <td>12.7506</td>\n",
       "      <td>160.0</td>\n",
       "      <td>0.0797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MPI_Wait</td>\n",
       "      <td>10.1933</td>\n",
       "      <td>9648.0</td>\n",
       "      <td>0.0011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MPI_Init</td>\n",
       "      <td>3.5711</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.8928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MPI_Isend</td>\n",
       "      <td>0.6676</td>\n",
       "      <td>9672.0</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>others</td>\n",
       "      <td>1.1138</td>\n",
       "      <td>10741.0</td>\n",
       "      <td>0.0769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Function  Total Time (s)  Call Count  Average Time (s)\n",
       "0  MPI_File_write_at_all         20.8652       160.0            0.1304\n",
       "1   MPI_File_read_at_all         12.7506       160.0            0.0797\n",
       "2               MPI_Wait         10.1933      9648.0            0.0011\n",
       "3               MPI_Init          3.5711         4.0            0.8928\n",
       "4              MPI_Isend          0.6676      9672.0            0.0001\n",
       "5                 others          1.1138     10741.0            0.0769"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beautify_df(calculate_accumulated_function_time(otf2_trace), top_n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100611\n"
     ]
    }
   ],
   "source": [
    "def list_all_events(trace_file_path: str):\n",
    "    \"\"\"\n",
    "    List all events from an OTF2 trace file.\n",
    "    \n",
    "    Args:\n",
    "        trace_file_path (str): Path to the OTF2 trace file\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of all events found in the trace file\n",
    "    \"\"\"\n",
    "    # Validate input file\n",
    "    if not trace_file_path.endswith('.otf2'):\n",
    "        raise ValueError(\"Input file must be an .otf2 trace file\")\n",
    "    \n",
    "    if not os.path.exists(trace_file_path):\n",
    "        raise FileNotFoundError(f\"Trace file not found: {trace_file_path}\")\n",
    "    \n",
    "    event_list = []\n",
    "    with otf2.reader.open(trace_file_path) as trace:\n",
    "        for _, event in trace.events:\n",
    "            event_list.append(event)\n",
    "    \n",
    "    return event_list\n",
    "\n",
    "# Example usage\n",
    "all_events = list_all_events(otf2_trace)\n",
    "print(len(all_events))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_io_bandwidth(trace_file_path: str):\n",
    "    \"\"\"\n",
    "    Calculate I/O bandwidth from OTF2 trace file.\n",
    "    \n",
    "    Args:\n",
    "        trace_file_path (str): Path to the OTF2 trace file\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing bandwidth metrics\n",
    "    \"\"\"\n",
    "    # Initialize storage for I/O operations\n",
    "    io_ops = {\n",
    "        'read': [],\n",
    "        'write': []\n",
    "    }\n",
    "    \n",
    "    with otf2.reader.open(trace_file_path) as trace:\n",
    "        # Track ongoing operations by matching_id\n",
    "        ongoing_ops = {}\n",
    "        \n",
    "        for _, event in trace.events:\n",
    "            if isinstance(event, otf2.events.IoOperationBegin):\n",
    "                # Store operation start info\n",
    "                ongoing_ops[event.matching_id] = {\n",
    "                    'start_time': event.time,\n",
    "                    'bytes_requested': event.bytes_request,\n",
    "                    'mode': event.mode\n",
    "                }\n",
    "                \n",
    "            elif isinstance(event, otf2.events.IoOperationComplete):\n",
    "                if event.matching_id in ongoing_ops:\n",
    "                    start_info = ongoing_ops[event.matching_id]\n",
    "                    duration = event.time - start_info['start_time']\n",
    "                    bytes_transferred = event.bytes_result\n",
    "                    \n",
    "                    # Calculate bandwidth in MB/s\n",
    "                    if duration > 0:\n",
    "                        bandwidth = (bytes_transferred / (1024 * 1024)) / (duration * 1e-9)\n",
    "                        \n",
    "                        # Store operation details\n",
    "                        op_type = 'read' if start_info['mode'] == otf2.IoOperationMode.READ else 'write'\n",
    "                        io_ops[op_type].append({\n",
    "                            'bytes': bytes_transferred,\n",
    "                            'duration_ns': duration,\n",
    "                            'bandwidth_mbs': bandwidth\n",
    "                        })\n",
    "                    \n",
    "                    del ongoing_ops[event.matching_id]\n",
    "\n",
    "    # Calculate aggregate metrics\n",
    "    metrics = {\n",
    "        'read': {\n",
    "            'total_bytes': sum(op['bytes'] for op in io_ops['read']),\n",
    "            'total_duration_ns': sum(op['duration_ns'] for op in io_ops['read']),\n",
    "            'avg_bandwidth_mbs': 0,\n",
    "            'peak_bandwidth_mbs': max((op['bandwidth_mbs'] for op in io_ops['read']), default=0)\n",
    "        },\n",
    "        'write': {\n",
    "            'total_bytes': sum(op['bytes'] for op in io_ops['write']),\n",
    "            'total_duration_ns': sum(op['duration_ns'] for op in io_ops['write']), \n",
    "            'avg_bandwidth_mbs': 0,\n",
    "            'peak_bandwidth_mbs': max((op['bandwidth_mbs'] for op in io_ops['write']), default=0)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Calculate average bandwidth\n",
    "    for op_type in ['read', 'write']:\n",
    "        if metrics[op_type]['total_duration_ns'] > 0:\n",
    "            metrics[op_type]['avg_bandwidth_mbs'] = \\\n",
    "                (metrics[op_type]['total_bytes'] / (1024 * 1024)) / \\\n",
    "                (metrics[op_type]['total_duration_ns'] * 1e-9)\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_io_bandwidth_by_size(trace_file_path: str):\n",
    "    \"\"\"\n",
    "    Calculate I/O bandwidth grouped by transaction sizes from OTF2 trace file.\n",
    "    \n",
    "    Args:\n",
    "        trace_file_path (str): Path to the OTF2 trace file\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing bandwidth metrics per transaction size\n",
    "    \"\"\"\n",
    "    # Initialize storage for I/O operations by size\n",
    "    io_ops_by_size = {\n",
    "        'read': {},  # Will store operations grouped by size\n",
    "        'write': {}  # Will store operations grouped by size\n",
    "    }\n",
    "    \n",
    "    with otf2.reader.open(trace_file_path) as trace:\n",
    "        # Track ongoing operations by matching_id\n",
    "        ongoing_ops = {}\n",
    "        \n",
    "        for _, event in trace.events:\n",
    "            if isinstance(event, otf2.events.IoOperationBegin):\n",
    "                # Store operation start info\n",
    "                ongoing_ops[event.matching_id] = {\n",
    "                    'start_time': event.time,\n",
    "                    'bytes_requested': event.bytes_request,\n",
    "                    'mode': event.mode\n",
    "                }\n",
    "                \n",
    "            elif isinstance(event, otf2.events.IoOperationComplete):\n",
    "                if event.matching_id in ongoing_ops:\n",
    "                    start_info = ongoing_ops[event.matching_id]\n",
    "                    duration = event.time - start_info['start_time']\n",
    "                    bytes_transferred = event.bytes_result\n",
    "                    \n",
    "                    # Calculate bandwidth in MB/s\n",
    "                    if duration > 0:\n",
    "                        bandwidth = (bytes_transferred / (1024 * 1024)) / (duration * 1e-9)\n",
    "                        \n",
    "                        # Store operation details grouped by size\n",
    "                        op_type = 'read' if start_info['mode'] == otf2.IoOperationMode.READ else 'write'\n",
    "                        size_key = bytes_transferred  # Use actual transfer size as key\n",
    "                        \n",
    "                        if size_key not in io_ops_by_size[op_type]:\n",
    "                            io_ops_by_size[op_type][size_key] = []\n",
    "                            \n",
    "                        io_ops_by_size[op_type][size_key].append({\n",
    "                            'bytes': bytes_transferred,\n",
    "                            'duration_ns': duration,\n",
    "                            'bandwidth_mbs': bandwidth\n",
    "                        })\n",
    "                    \n",
    "                    del ongoing_ops[event.matching_id]\n",
    "\n",
    "    # Calculate metrics per size\n",
    "    metrics_by_size = {\n",
    "        'read': {},\n",
    "        'write': {}\n",
    "    }\n",
    "    \n",
    "    for op_type in ['read', 'write']:\n",
    "        for size, operations in io_ops_by_size[op_type].items():\n",
    "            metrics_by_size[op_type][size] = {\n",
    "                'count': len(operations),\n",
    "                'total_bytes': sum(op['bytes'] for op in operations),\n",
    "                'total_duration_ns': sum(op['duration_ns'] for op in operations),\n",
    "                'avg_bandwidth_mbs': 0,\n",
    "                'min_bandwidth_mbs': min((op['bandwidth_mbs'] for op in operations), default=0),\n",
    "                'max_bandwidth_mbs': max((op['bandwidth_mbs'] for op in operations), default=0),\n",
    "                'std_bandwidth_mbs': 0\n",
    "            }\n",
    "            \n",
    "            # Calculate average bandwidth\n",
    "            if metrics_by_size[op_type][size]['total_duration_ns'] > 0:\n",
    "                metrics_by_size[op_type][size]['avg_bandwidth_mbs'] = \\\n",
    "                    (metrics_by_size[op_type][size]['total_bytes'] / (1024 * 1024)) / \\\n",
    "                    (metrics_by_size[op_type][size]['total_duration_ns'] * 1e-9)\n",
    "            \n",
    "            # Calculate standard deviation of bandwidth\n",
    "            if len(operations) > 1:\n",
    "                mean = metrics_by_size[op_type][size]['avg_bandwidth_mbs']\n",
    "                variance = sum((op['bandwidth_mbs'] - mean) ** 2 for op in operations) / (len(operations) - 1)\n",
    "                metrics_by_size[op_type][size]['std_bandwidth_mbs'] = variance ** 0.5\n",
    "    \n",
    "    return metrics_by_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'read': {42515280: {'count': 40,\n",
       "   'total_bytes': 1700611200,\n",
       "   'total_duration_ns': 6687167402,\n",
       "   'avg_bandwidth_mbs': 242.5285814061953,\n",
       "   'min_bandwidth_mbs': 75.58547166298375,\n",
       "   'max_bandwidth_mbs': 298.51505473358645,\n",
       "   'std_bandwidth_mbs': 34.97532679883168}},\n",
       " 'write': {42515280: {'count': 40,\n",
       "   'total_bytes': 1700611200,\n",
       "   'total_duration_ns': 10879508135,\n",
       "   'avg_bandwidth_mbs': 149.07192526611522,\n",
       "   'min_bandwidth_mbs': 64.62763295368534,\n",
       "   'max_bandwidth_mbs': 162.2347998607631,\n",
       "   'std_bandwidth_mbs': 15.680638135255899}}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_io_bandwidth_by_size(otf2_trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'otf2.definitions' from '/usr/local/lib/python3.12/site-packages/otf2/definitions.py'>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "otf2.definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class Otf2Paradigm(Enum):\n",
    "    \"\"\"\n",
    "    Enumeration for different I/O paradigms with their identifications in OTF2 trace files.\n",
    "    \n",
    "    Attributes:\n",
    "        MPIIO (str): Represents the MPI-IO paradigm.\n",
    "        POSIX (str): Represents the POSIX paradigm.\n",
    "    \"\"\"\n",
    "    MPIIO = 'MPI-IO'\n",
    "    POSIX = 'POSIX'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mpi_io_bandwidth_by_size(trace_file_path: str, paradigm: Otf2Paradigm) -> dict:\n",
    "    \"\"\"\n",
    "    Calculate I/O bandwidth specifically for MPI I/O operations grouped by transaction size.\n",
    "    \n",
    "    Args:\n",
    "        trace_file_path (str): Path to the OTF2 trace file\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing bandwidth metrics per transaction size\n",
    "    \"\"\"\n",
    "    # Initialize storage for I/O operations by size\n",
    "    io_ops_by_size = {\n",
    "        'read': defaultdict(list),\n",
    "        'write': defaultdict(list)\n",
    "    }\n",
    "    \n",
    "    with otf2.reader.open(trace_file_path) as trace:\n",
    "        # Find MPI I/O paradigm definition\n",
    "        mpi_io_paradigm = None\n",
    "        for trace_paradigm in trace.definitions.io_paradigms:\n",
    "            if trace_paradigm.identification == paradigm.value:\n",
    "                mpi_io_paradigm = trace_paradigm\n",
    "                break\n",
    "                \n",
    "        if mpi_io_paradigm is None:\n",
    "            raise ValueError(\"Given MPI I/O paradigm not found in trace\")\n",
    "            \n",
    "        # Track ongoing operations by matching_id\n",
    "        ongoing_ops = {}\n",
    "        \n",
    "        for location, event in trace.events:\n",
    "            if isinstance(event, otf2.events.IoOperationBegin):\n",
    "                # Only track MPI I/O operations\n",
    "                if event.handle.io_paradigm == mpi_io_paradigm:\n",
    "                    ongoing_ops[event.matching_id] = {\n",
    "                        'start_time': event.time,\n",
    "                        'bytes_requested': event.bytes_request,\n",
    "                        'mode': event.mode\n",
    "                    }\n",
    "                    \n",
    "            elif isinstance(event, otf2.events.IoOperationComplete):\n",
    "                if event.matching_id in ongoing_ops:\n",
    "                    start_info = ongoing_ops[event.matching_id]\n",
    "                    duration = event.time - start_info['start_time']\n",
    "                    bytes_transferred = event.bytes_result\n",
    "                    \n",
    "                    # Calculate bandwidth in MB/s\n",
    "                    if duration > 0:\n",
    "                        bandwidth = (bytes_transferred / (1024 * 1024)) / (duration * 1e-9)\n",
    "                        \n",
    "                        # Store operation details grouped by size\n",
    "                        if start_info['mode'] == otf2.IoOperationMode.READ:\n",
    "                            op_type = 'read' \n",
    "                        elif start_info['mode'] == otf2.IoOperationMode.WRITE:\n",
    "                            op_type = 'write'\n",
    "                        else:\n",
    "                            print(f\"Unknown operation mode: {start_info['mode']}\")\n",
    "                            continue\n",
    "                    \n",
    "                        io_ops_by_size[op_type][bytes_transferred].append({\n",
    "                            'bytes': bytes_transferred,\n",
    "                            'duration_ns': duration,\n",
    "                            'bandwidth_mbs': bandwidth\n",
    "                        })\n",
    "                    \n",
    "                    del ongoing_ops[event.matching_id]\n",
    "\n",
    "    # Calculate metrics per size\n",
    "    metrics = {\n",
    "        'read': {},\n",
    "        'write': {}\n",
    "    }\n",
    "    \n",
    "    for op_type in ['read', 'write']:\n",
    "        for size, operations in io_ops_by_size[op_type].items():\n",
    "            metrics[op_type][size] = {\n",
    "                'count': len(operations),\n",
    "                'total_bytes': sum(op['bytes'] for op in operations),\n",
    "                'total_duration_ns': sum(op['duration_ns'] for op in operations),\n",
    "                'avg_bandwidth_mbs': 0,\n",
    "                'min_bandwidth_mbs': min((op['bandwidth_mbs'] for op in operations), default=0),\n",
    "                'max_bandwidth_mbs': max((op['bandwidth_mbs'] for op in operations), default=0),\n",
    "                'std_bandwidth_mbs': 0\n",
    "            }\n",
    "            \n",
    "            # Calculate average bandwidth\n",
    "            if metrics[op_type][size]['total_duration_ns'] > 0:\n",
    "                metrics[op_type][size]['avg_bandwidth_mbs'] = \\\n",
    "                    (metrics[op_type][size]['total_bytes'] / (1024 * 1024)) / \\\n",
    "                    (metrics[op_type][size]['total_duration_ns'] * 1e-9)\n",
    "            \n",
    "            # Calculate standard deviation of bandwidth\n",
    "            if len(operations) > 1:\n",
    "                mean = metrics[op_type][size]['avg_bandwidth_mbs']\n",
    "                variance = sum((op['bandwidth_mbs'] - mean) ** 2 for op in operations) / (len(operations) - 1)\n",
    "                metrics[op_type][size]['std_bandwidth_mbs'] = variance ** 0.5\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'read': {42515280: {'count': 40,\n",
       "   'total_bytes': 1700611200,\n",
       "   'total_duration_ns': 6687167402,\n",
       "   'avg_bandwidth_mbs': 242.5285814061953,\n",
       "   'min_bandwidth_mbs': 75.58547166298375,\n",
       "   'max_bandwidth_mbs': 298.51505473358645,\n",
       "   'std_bandwidth_mbs': 34.97532679883168}},\n",
       " 'write': {42515280: {'count': 40,\n",
       "   'total_bytes': 1700611200,\n",
       "   'total_duration_ns': 10879508135,\n",
       "   'avg_bandwidth_mbs': 149.07192526611522,\n",
       "   'min_bandwidth_mbs': 64.62763295368534,\n",
       "   'max_bandwidth_mbs': 162.2347998607631,\n",
       "   'std_bandwidth_mbs': 15.680638135255899}}}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_mpi_io_bandwidth_by_size(otf2_trace, Otf2Paradigm.MPIIO)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
